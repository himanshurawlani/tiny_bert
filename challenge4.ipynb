{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<b>IMPORTANT</b>: Run the below cell to import the modules from previous completed challenge."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%run solution1.ipynb\n",
        "%run solution2.ipynb\n",
        "%run solution3.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PY8zJ3sk9k5l"
      },
      "source": [
        "# **Coding Challenge Part 4: Learning sentence embedding using a contrastive approach based on NLI dataset [3 Points]**\n",
        "\n",
        "**Please DO NOT use additional library except the ones that are imported!!**\n",
        "\n",
        "In this part, you are asked to explore another method that leverages a contrastive approach using NLI dataset.\n",
        "\n",
        "Tasks **[3 Points]** :\n",
        "\n",
        "*   Generate a dataloader if this is required for your approach\n",
        "*   Construct a BERT based model using a contrastive method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b83lJraO9ngO"
      },
      "outputs": [],
      "source": [
        " #TODO: add code to load NLI dataset in required format\n",
        " ###    if load_nli_dataset(..) is not appropriate for your method\n",
        "\n",
        "class BertContrastive(nn.Module):\n",
        "    #TODO: add __init__ to construct BertContrastive based on given pretrained BERT\n",
        "    #TODO: add code for forward pass that returns the loss value\n",
        "    #TODO: add aditional method if required"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uz-_sNPt9rio"
      },
      "source": [
        "**Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8UgzRYcQ9vJ5"
      },
      "outputs": [],
      "source": [
        "#INFO: model and training configs\n",
        "model_name = 'prajjwal1/bert-tiny'\n",
        "num_epochs = 3\n",
        "batch_size = 8\n",
        "num_labels =3\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "bert_config = {\"hidden_size\": 128, \"num_attention_heads\": 2, \"num_hidden_layers\": 2, \"intermediate_size\": 512, \"vocab_size\": 30522}\n",
        "bert_path = 'bert_tiny.bin'\n",
        "\n",
        "#WARNING: Change this code if you implemented a different nli loader for this part\n",
        "nli_dataset = load_nli_dataset('AllNLI.tsv.gz')\n",
        "\n",
        "#INFO: tokenize dataset\n",
        "#WARNING: Use only first 50000 samples and maximum sequence lenght of 128\n",
        "tokenized_train = tokenize_sentence_pair_dataset(nli_dataset['train'][:50000], tokenizer, max_length=128)\n",
        "\n",
        "#INFO: generate train_dataloader\n",
        "train_dataloader = get_dataloader(tokenized_train, batch_size=batch_size)\n",
        "\n",
        "#TODO: Create a BertContrastive with required parameters\n",
        "###    Replace None with required input based on yor implementation\n",
        "bert_contrastive = BertContrastive(None)\n",
        "\n",
        "#INFO: create optimizer and run training loop\n",
        "optimizer = AdamW(bert_contrastive.parameters(), lr=5e-5)\n",
        "train_loop(bert_contrastive, optimizer, train_dataloader, num_epochs, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzpGJpXe90qB"
      },
      "source": [
        "**Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g69xrkFl9yQP"
      },
      "outputs": [],
      "source": [
        "#TODO: run evaluation loop\n",
        "result_from_contrastive = eval_loop(model, test_dataloader, device)\n",
        "print(f'\\nPearson correlation: {result_from_contrastive[0]:.2f}\\nSpearman correlation: {result_from_contrastive[1]:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SbaQse096bx"
      },
      "source": [
        "# **Coding Challenge Part 5: Comparison [1 Point]**\n",
        "\n",
        "In the final part of the coding challenge, you are asked to compare the result of pretrained BERT, classification based BERT, and contrastive method based BERT.\n",
        "\n",
        "These are the tasks **[1 Point]**:\n",
        "\n",
        "\n",
        "*   Plot the result for each model\n",
        "*   Explain the difference between methods and their impact on the result and comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9__3lchp97BM"
      },
      "source": [
        "# **[OPTIONAL] Explore an alternative way to improve sentence encoder in terms of *performance* or *efficiency* [6 Points]**\n",
        "\n",
        "Potential directions:\n",
        "*   Improve the methodology to compute higher quality sentence embeddings  \n",
        "*   Improve the efficiency during fine-tuning in terms of memory or training time\n",
        "*   Use different machine learning methods that leverages other resources such as auxillary/teacher models\n",
        "*   Use different datasets with other training objectives\n",
        "\n",
        "\n",
        "**You can use any additional model, dataset, library or package for this part!!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Study resources\n",
        "\n",
        "1. Contrastive loss: https://www.sbert.net/examples/training/quora_duplicate_questions/README.html#constrative-loss\n",
        "2. MultipleNegativesRanking Loss: https://www.sbert.net/examples/training/nli/README.html#multiplenegativesrankingloss"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
