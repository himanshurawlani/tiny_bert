{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<b>IMPORTANT</b>: Run the below cell to import the modules from previous completed challenge."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%run solution1.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8dEdZoc815Y"
      },
      "source": [
        "# **Coding Challenge Part 2: Evaluate a pretrained BERT model on STS benchmark [4 points]**\n",
        "\n",
        "**Please do not use additional library except the ones that are imported!!**\n",
        "\n",
        "In this part, we are going to evaluate a pretrained BERT model on STS benchmark without applying any additional training. For the evaluation we provide Pearson/Spearman correlation functions and cosine similarity method.\n",
        "\n",
        "Tasks:\n",
        "\n",
        "*   **[2 Points]** Prepare an evaluation data loader and evaluation loop: Read in the STS data, tokenize it as shown in the example,  generate the dataloader and return Pearson and Spearman correlation scores.\n",
        "*   **[1 Point]** Implement cosine similarity function, explained as TODO\n",
        "\n",
        "**[1 Point] Question**: What is the difference between Pearson and Spearman correlation, and why you might want to evaluate using both metrics?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puz1zbYQ84cn"
      },
      "source": [
        "**Semantic Textual Similarity (STS) benchmark:**\n",
        "STS dataset consists of a set of sentence pairs with a semantic similarity scores for each pair. We want to use this dataset to evaluate the quality of a sentence encoder.\n",
        "\n",
        "Dataset includes:\n",
        "\n",
        "*   Sentence pair: (sentence1, sentence2)\n",
        "*   Similarity score: ranging 1 to 5 where 5 corresponds highest similarity\n",
        "*   Splits: train, dev, test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfeR2h9T86dn"
      },
      "source": [
        "**Download datasets**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXAtOSWA88vd"
      },
      "outputs": [],
      "source": [
        "!wget https://sbert.net/datasets/stsbenchmark.tsv.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pz2ChjrE9AdV"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('stsbenchmark.tsv.gz', nrows=5, compression='gzip', delimiter='\\t', quoting=csv.QUOTE_NONE)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQKjkQ7a9Du2"
      },
      "outputs": [],
      "source": [
        "def load_sts_dataset(file_name):\n",
        "  #TODO: add code to load STS dataset in required format\n",
        "  sts_samples = {'test': []}\n",
        "  return sts_samples\n",
        "\n",
        "\n",
        "def tokenize_sentence_pair_dataset(dataset, tokenizer, max_length=512):\n",
        "  #TODO: add code to generate tokenized version of the dataset\n",
        "  tokenized_dataset = []\n",
        "  return tokenized_dataset\n",
        "\n",
        "\n",
        "def get_dataloader(tokenized_dataset, batch_size, shuffle=False):\n",
        "  return DataLoader(tokenized_dataset, batch_size=batch_size, shuffle=shuffle)\n",
        "\n",
        "\n",
        "def cosine_sim(a, b):\n",
        "  # TODO: Implement cosine similarity function **from scrach**:\n",
        "  # This method should expect two 2D matrices (batch, vector_dim) and\n",
        "  # return a 2D matrix (batch, batch) that contains all pairwise cosine similarities\n",
        "  return torch.zeros(a.shape[0], a.shape[0])\n",
        "\n",
        "\n",
        "def eval_loop(model, eval_dataloader, device):\n",
        "  #TODO: add code to for evaluation loop\n",
        "  #TODO: Use cosine_sim function above as distance metric for pearsonr and spearmanr functions that are imported\n",
        "  return [eval_pearson_cosine, eval_spearman_cosine]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IT9xuo9k9Edb"
      },
      "source": [
        "**Evaluation**\n",
        "\n",
        "Expected result:\n",
        "\n",
        "Pearson correlation: 0.32\n",
        "\n",
        "Spearman correlation: 0.33"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZDlpcUmL9HH5"
      },
      "outputs": [],
      "source": [
        "#INFO: model and tokenizer\n",
        "model_name = 'prajjwal1/bert-tiny'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "#INFO: load bert\n",
        "bert_config = {\"hidden_size\": 128, \"num_attention_heads\": 2, \"num_hidden_layers\": 2, \"intermediate_size\": 512, \"vocab_size\": 30522}\n",
        "bert = Bert(bert_config).load_model('bert_tiny.bin')\n",
        "\n",
        "#INFO: load dataset\n",
        "sts_dataset = load_sts_dataset('stsbenchmark.tsv.gz')\n",
        "\n",
        "#INFO: tokenize dataset\n",
        "tokenized_test = tokenize_sentence_pair_dataset(sts_dataset['test'], tokenizer)\n",
        "\n",
        "#INFO: generate dataloader\n",
        "test_dataloader = get_dataloader(tokenized_test, batch_size=1)\n",
        "\n",
        "#INFO: run evaluation loop\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "results_from_pretrained = eval_loop(bert, test_dataloader, device)\n",
        "\n",
        "print(f'\\nPearson correlation: {results_from_pretrained[0]:.2f}\\nSpearman correlation: {results_from_pretrained[1]:.2f}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
